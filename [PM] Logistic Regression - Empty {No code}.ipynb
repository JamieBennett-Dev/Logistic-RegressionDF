{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad54d3b8",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">\n",
    "<img src=\"https://github.com/digital-futures-academy/DataScienceMasterResources/blob/main/Resources/datascience-notebook-header.png?raw=true\"\n",
    "     alt=\"DigitalFuturesLogo\"\n",
    "     style=\"float: center; margin-right: 10px;\" />\n",
    "</p>\n",
    "\n",
    "## Digital Futures Data Programme\n",
    "### Logistic Regression\n",
    "#### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bc6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "## Importing the big 4 - Pandas, Numpy, Seaborn & matplotlib\n",
    "import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt\n",
    "## Import the metrics we'll be using\n",
    "from sklearn import metrics\n",
    "## Import Logistic Regression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3ddb8",
   "metadata": {},
   "source": [
    "## 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98118214",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87699cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore the first couple of entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a292844",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore the last couple of entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780bf3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What's the dimension of our data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1000282",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What columns are we using?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "954b03cf",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/digital-futures-academy/DataScienceMasterResources/blob/main/Resources/Titanic.png?raw=True\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9285a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What are the nulls & data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6406ea4",
   "metadata": {},
   "source": [
    "#### Data cleaning & prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d968e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many passengers survived v.s perished?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the unique values for sex -- all other fields are either not categories (i.e take a lot of different values)\n",
    "## or their unique values are already explained in the data dictionary (survived, ticket class, embarked)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c420f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To work with logistic regression, we will need our values to be numerical. There are a couple of values that\n",
    "## concern us. The first (and easiest to quickfix) is sex, which is binary in this data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8040c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's check the unique values again, to see if it worked\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c324201",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can now start thinking about the other columns, such as age. This is certainly a continuous range, so\n",
    "## we could investigate the distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ce756",
   "metadata": {},
   "source": [
    "> What are your observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Another way to view distributions, but for categories is to take the value counts. Remember what we did for survived?\n",
    "## That quickly becomes quite silly for 5 categories.. or 8, or 10. So here's a much better way using the value_counts() method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can do the same for parch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a69d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For these values, we can visualise them most easily using a barplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79f66cf",
   "metadata": {},
   "source": [
    "> If we had (much!) fewer observations, we could also visualise them using a dotplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c449f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Typically, we won't be interested in looking at just the distribution of a single feature.\n",
    "## It's more interesting to inspect how it compares against other features in our data, and look for patterns or correlations\n",
    "## The easiest visual tool to achieve that is our trusty pairplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Even more interesting, what if we want a broad, wholistic view of our data? This is where the correlation\n",
    "## matrix comes in - providing the (default: Pearson) correlation between each of the features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1591f271",
   "metadata": {},
   "source": [
    "> What are your observations based on this?\n",
    "\n",
    "<details><summary> Click me for solutions </summary>\n",
    "    \n",
    "* Survived 1 -- means it's highly likely that Sex 1: They survived :) -- means Female\n",
    "\n",
    "\n",
    "* Survived 0 -- means it's highly likely that Sex 0: They didn't survive :( -- means Male\n",
    "    \n",
    "The bigger the passenger class indicates a lower fare paid (-.42 corr) and a lower change of surviving (-.29 corr)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3b081",
   "metadata": {},
   "source": [
    "#### Deeper dive - tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tickets will be tricky, for three main reasons:\n",
    "## 1. They're likely too many to categorise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. They're probably not numerical (or contain numbers, but not only)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f05855",
   "metadata": {},
   "source": [
    "_And 3. How do we actually extract signal from these?.._\n",
    "\n",
    "One strategy is.. <s>ignorance is bliss</s> -- let's just remove the column!\n",
    "\n",
    "Another strategy: What if we were to just focus on extracting the letters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We notice that some tickets have letters, others don't. The numbers are clearly an identifier (so bear no signal)\n",
    "## but could the letters indicate anything about the ticket? We could explore this.\n",
    "## Let's use (the absolute best tool) REGEX! ### import re\n",
    "\n",
    "import re\n",
    "def extract_letters(x):\n",
    "    return re.sub(r'[\\d\\s]', r'', x) if x==x else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's test it on an example\n",
    "## Ticket name: 752382 AB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seems to be working! Let's apply it to the whole column\n",
    "## Save the results in a new column, let's call it df['Ticket_letters']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3fbfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do .head() to view the new data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42cd823",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looks great! But what does the distribution roughly look like?\n",
    "## Again, we could use .value_counts() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be0ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TODO\n",
    "\n",
    "## Distribution plots (pairlpots, histograms)\n",
    "\n",
    "## Boxplots -- super important to look for outliers!\n",
    "\n",
    "## Embarked into category -- address the nulls for it separately here (S, C and Q)\n",
    "\n",
    "## Fix the extract_letters function (we're carrying dots as well) - or do we need to?\n",
    "\n",
    "## ...\n",
    "\n",
    "## ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1dc02",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's first remember what are our potential features\n",
    "## We can do that using the .columns attribute\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd85745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We'll only extract a couple of these to use. Which ones?\n",
    "## Clearly, the passenger ID is not of any use. Survived is our target - but we'll keep it in for now, and remove it later.\n",
    "## Name also acts as an ID (and offers no signal).\n",
    "## Ticket and Cabin fall into their own category: There _may_ be signal to be extracted out of them one way or another,\n",
    "## but we didn't do so - so for now, we won't use them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d12806",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's save the dataframe we'll use -- don't forget to use .copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c167fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's do .head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a5309",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uh-oh.. I can see some null values. Do we remember how to check the nulls? There's many ways\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0bcb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's do the simplest thing: drop the nulls - since they come in negligible amounts\n",
    "\n",
    "\n",
    "## We can also create y now, the target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995dc702",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is why we kept 'Survived' in until now - since we were going to drop nulls. If we dropped the nulls and y was separate,\n",
    "## we would have a dimension mismatch. Still, let's make sure that's not the case.\n",
    "## The length of y (# of targets) should match the # of rows in the data (# of observations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e164ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fantastic! But let's not forget to drop the target now, so we only keep our features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There is one final small problem.. we mentioned this a couple of times: our model won't work until we have numerical data only\n",
    "## Using the .info() method or the .dtypes attribute we can see Embarked is still a category on its own. \n",
    "## We'll use OHE to fix this quickly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finally, let's view our data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8726c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Are we sure there are no nulls left? No non-numerical observations? Final check!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74382803",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TODO\n",
    "\n",
    "## All feature engineering should go in a single, easily accessible & reproducible function\n",
    "\n",
    "## Null handling - we just discarded them: was this the best way to handle them in this case?\n",
    "\n",
    "## Definitely have a look at the data distribution - scaling! (StandardScaler, MinMaxScaler, LogScaler)\n",
    "\n",
    "## Better data extraction -- feature selection\n",
    "\n",
    "## Model selection (more advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddadc19f",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like all good things in Python, we only need 1 line ~ Guido Van Rossum\n",
    "## We just need to create a LogisticRegression() object. All parameters have set defaults, so no need to do anything else,\n",
    "## but we can always improve the model by considering the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1c8b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## So, we have an empty LogisticRegression() object. This needs to be fit on our data first and foremost\n",
    "## Since we're using sklearn, the rule of thumb is: first parameter = features, second parameter = target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ebace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now that the model is fit, we can make our prediction. Fortunately, this too is a single line of code!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7772ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is this?! Why do we get two sets of values for each prediction?\n",
    "## Ohh that's right - one is the probability of outcome 0 (perished), the other the probability of outcome 1 (survived)\n",
    "## Since these are the only 2 options, it adds up (quite literally! They add up to 1)\n",
    "\n",
    "## Let's store them in 2 columns then, called 'prob_perish' and 'prob_surv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## .head() to check our progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00137205",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fantastic! However.. we still need to make a binary prediction: Has this passenger survived or not?\n",
    "## This will be based on the probabilities offered. If prob_surv > .5, we can say they survived.\n",
    "## Why .5? This is what we call a CUT-OFF POINT - and it's yet another parameter we can pick! We'll try .5, but it might indeed\n",
    "## not be the optimum value. Maybe we need to use .6, maybe .65: You should explore this on your own\n",
    "## We'll store our prediction in a column called 'y_pred' and use the np.where() method to do so\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db5b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finally, now we should be ready! Let's do a final .head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705c459",
   "metadata": {},
   "source": [
    "> Looks right, at least in theory. The question on everyone's lips now should be: How well did we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d41df",
   "metadata": {},
   "source": [
    "## 4. Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We'll use our trusty confusion matrix to answer the question above. Let's first have a look at it on its own\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are 4 main metrics we're interested in at this stage: accuracy, precision, recall and F1.\n",
    "## The 'metrics' module from sklearn covers all of them (and more!) So we can use a function like the one below\n",
    "\n",
    "def get_results(actual, predicted):\n",
    "    print(\"The confusion matrix for your predictions is:\")\n",
    "    print(metrics.confusion_matrix(actual, predicted), \"\\n\")\n",
    "    print(f'The accuracy of your model is: {metrics.accuracy_score(actual, predicted)}')\n",
    "    print(f'The recall of your model is: {metrics.recall_score(actual, predicted)}')\n",
    "    print(f'The precision of your model is: {metrics.precision_score(actual, predicted)}')\n",
    "    print(f'The F1-score of your model is: {metrics.f1_score(actual, predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d280cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, we simply apply the function on our predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f158c4",
   "metadata": {},
   "source": [
    "> What do you notice at this stage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not bad! Can certainly do better, but not bad. The function is quite farfetched though\n",
    "## It's good that we can take all metrics separately, but surely there must be an easier way.\n",
    "## The classification report provides just that! Don't forget to add print() otherwise it will be hard to look at :p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e428a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Much better! I really like heatmaps and pretty colours though\n",
    "## Luckily, 'metrics' has us covered once again, using the ConfusionMatrixDisplay tool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c50163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO\n",
    "\n",
    "## Explore the cutoff point\n",
    "\n",
    "## Explore feature selection, standardization -- everything that went into Feature Engineering\n",
    "\n",
    "## Explore more metrics! ROC/AUC -- Maximizing the area under the curve (AUC): AUC > .8 usually really good\n",
    "\n",
    "## Predicted values v.s Actual values distribution - what would a good distribution look like?\n",
    "\n",
    "## Play with hyperparameters for the logistic regression\n",
    "\n",
    "## ...\n",
    "\n",
    "## ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b585c9c",
   "metadata": {},
   "source": [
    "## Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31483805",
   "metadata": {},
   "source": [
    "Can you do better? Start by following the advice given above for each step, and explore on your own.\n",
    "\n",
    "Feeling like you nailed it? Or just want to check yourself? Try running it on the test dataset! You can find it [here](https://noodle.digitalfutures.com/course/view.php?id=81). Wait! This data.. doesn't have the survived column? That's right - because this is actually part of a [Kaggle competition](https://www.kaggle.com/datasets). You too can participate, and you can submit as many solutions as you want! Once you come up with an improved performance on your training data, make sure to apply it to the test, generate your predictions and [submit them to see how you did](https://www.kaggle.com/competitions/tabular-playground-series-apr-2021/data). The competition ended, but you can always do a 'late submission' just to test yourself :)\n",
    "\n",
    "Why don't we start with our base model as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e96f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d406207",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We'll do the cleaning properly all in 1 go, since we now know what to do\n",
    "def cleaning_prep(df):\n",
    "    df['Sex'] = df['Sex'].map({'male':0, 'female':1}) ## Change sex to numbers\n",
    "    Features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'] ## select features\n",
    "    df = df[Features].copy() ## only use selected features\n",
    "    df = pd.get_dummies(data = df, columns = ['Embarked'], prefix='Emb', drop_first=True) ## OHE Embark\n",
    "    df = df.fillna(0) ## We cannot drop the nulls, since we need the whole data to submit\n",
    "    return df\n",
    "df_test = cleaning_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee39e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's apply the model and get our predictions: Remember, we use the same parameters as we did in the training case\n",
    "## IMPORTANT: We already have the logistic regression fit on the training set, we now only need to predict\n",
    "df_test[['prob_perish', 'prob_surv']] = lr.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4da0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we get our predictions:\n",
    "df_test['Survived'] = np.where(df_test['prob_surv']>.5, 1, 0)\n",
    "## We also need to grab the passengerID to match:\n",
    "df_test['PassengerId'] = df['PassengerId'][df['PassengerId'].index.isin(df_test.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save them as a csv file, to then be uploaded -- note: the submission only expects the ID & Survived column\n",
    "df_test[['PassengerId', 'Survived']].to_csv(\"Titanic_pred.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1ee4559",
   "metadata": {},
   "source": [
    "I now take my file and upload it here:\n",
    "<img src=\"https://github.com/digital-futures-academy/DataScienceMasterResources/blob/main/Resources/Titanic_upload1.png?raw=True\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b241d86d",
   "metadata": {},
   "source": [
    "And this is how we did:\n",
    "<img src=\"https://github.com/digital-futures-academy/DataScienceMasterResources/blob/main/Resources/Titanic_upload2.png?raw=True\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7934018d",
   "metadata": {},
   "source": [
    "Now it's your turn! I'm sure you can do much better. Good luck :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671240f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d02ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb64305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32140d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1fd62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
